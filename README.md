# llm-law-qa
专用性大模型问答项目-法律

基于RAG框架，利用llamaIndex 大模型语言框架的智能文档问答系统

项目结构：
收集数据：
	数据集选择：
		公开法律文件集，例如：Pile-of-Law或LegalBench。也可以MMDocIR等多模态文档检索挑战赛的数据集，如研究报告，法律文件
	多模态数据提取：
		PyMuPDF4LLM
		提取的图片使用OCR；图表进一步视觉模型语言VLM理解并生成描述
	文本分块
	数据清洗
嵌入与知识库构建：
	多模态嵌入模型：
		pytorch支持的多模态嵌入模型-clip或专为文档理解设计的VLM
		优先选择在法律语料库预训练或微调的嵌入模型
	向量数据库：
		chromaDB，pinecone，Milvus...
		使用llmindex或langchain将生成的嵌入向量及原始文本/图片/表格内容存储到向量数据库
RAG管道构建
	检索器：
		使用langchain或llmindex构建自定义检索器，实现混合检索
		进阶想法：纠正性RAG-CRAG，检索阶段加入自我评估
	重排序器：
		重排序模型，最相关的排在前面
		进阶：自定义重排序器
	LLM集成：将重排序后的相关上下文与用户查询一起给LLM，生成最终
		选择开源LLM
		进阶：LLM微调
智能体与工具
	Langchin Agent：让LLM自动决定核何时以及如何使用外部工具
	工具定义：为法律问答系统定义工具
		条例查询工具：agent精确查询特定法律条文
		案例分析工具：
		定义解释工具：遇到不熟悉的法律术语，自动查询并解释其含义
	进阶想法：智能体驱动RAG。
部署与监控
	交互式web界面：使用Gradio或Streamlit构建一个用户友好的web应用，用户可以上传，提问并查看系统生成的答案及引用来源
	Dokcer打包，确保环境一致性和可移植性
	MLOps最佳实践：
		模型版本控制git追踪代码版本，考虑使用DVC管理数据集和模型版本，确保实验的可重现性
		持续监控：监控性能，数据漂移和系统延迟 PyTorch Profile性能分析
		自动化测试：为数据处理、模型推理和RAG管道的关键组件编写单元测试和集成测试
		CI/CD持续集成/持续部署：规划一个简化的CI/CD流程，例如每次提交后自动运行测试并构建Docker镜像